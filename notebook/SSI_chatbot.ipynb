{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ce1ea5cbcf04da28df8f5726b3f7c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4598918f0674aeb920b4c74d1e8c5c6",
              "IPY_MODEL_5a6025f60ebc4870bcf7c9ef9a3f10f8",
              "IPY_MODEL_59ff1aefaa8344b6918ef4e768907782"
            ],
            "layout": "IPY_MODEL_9479b060b23c46c0ab8c24b3fdfbeb18"
          }
        },
        "a4598918f0674aeb920b4c74d1e8c5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe73ac18b2794f84a85f1399e83c40ad",
            "placeholder": "​",
            "style": "IPY_MODEL_3ce95092c92541c18b8b5be6ed96fe89",
            "value": "Map: 100%"
          }
        },
        "5a6025f60ebc4870bcf7c9ef9a3f10f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_188fa50ba3e342f19d07f8f702d5ce9a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7a45f478ebf46aebe85288e690866da",
            "value": 5
          }
        },
        "59ff1aefaa8344b6918ef4e768907782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d709721ba77c44c9a0244b87b09d5d86",
            "placeholder": "​",
            "style": "IPY_MODEL_a8aa96959fcf41ff9a4d852c5f34b722",
            "value": " 5/5 [00:00&lt;00:00, 70.93 examples/s]"
          }
        },
        "9479b060b23c46c0ab8c24b3fdfbeb18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe73ac18b2794f84a85f1399e83c40ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce95092c92541c18b8b5be6ed96fe89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188fa50ba3e342f19d07f8f702d5ce9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a45f478ebf46aebe85288e690866da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d709721ba77c44c9a0244b87b09d5d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8aa96959fcf41ff9a4d852c5f34b722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9R5MSvKRewR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Surgical Site Infections (SSI) Chatbot Project\n",
        "\n",
        "This notebook demonstrates the process of creating a chatbot that provides information about Surgical Site Infections (SSI) using a fine-tuned BERT model.\n"
      ],
      "metadata": {
        "id": "sdJdaqUwRjhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install Necessary Libraries"
      ],
      "metadata": {
        "id": "_3zcz7RNRliz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPTkayUORpwR",
        "outputId": "335e7136-1ed1-486d-8577-a5bfdd4189fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Import Libraries\n"
      ],
      "metadata": {
        "id": "hdDUwiRPRyek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "DoBoQ1xWR0PN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "GxR3295KSCK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = [\n",
        "    {\"question\": \"What are Surgical Site Infections (SSIs)?\", \"answer\": \"Surgical Site Infections (SSIs) are infections that occur after surgery in the part of the body where the surgery took place.\"},\n",
        "    {\"question\": \"What are the common causes of SSIs?\", \"answer\": \"SSIs are typically caused by bacteria that enter the incision site during surgery or in the days following surgery.\"},\n",
        "    {\"question\": \"How can SSIs be prevented?\", \"answer\": \"SSIs can be prevented by maintaining proper hygiene, using sterile equipment, and administering antibiotics before surgery.\"},\n",
        "    {\"question\": \"What are the symptoms of SSIs?\", \"answer\": \"Symptoms of SSIs include redness and swelling at the incision site, pain or tenderness, and pus or drainage from the wound.\"},\n",
        "    {\"question\": \"How are SSIs treated?\", \"answer\": \"Treatment for SSIs typically involves antibiotics and, in some cases, additional surgery to remove infected tissue.\"}\n",
        "]\n",
        "\n",
        "data = {\"question\": [], \"context\": [], \"answer\": []}\n",
        "for item in dataset:\n",
        "    data[\"question\"].append(item[\"question\"])\n",
        "    data[\"context\"].append(\" \".join([q[\"answer\"] for q in dataset]))\n",
        "    data[\"answer\"].append(item[\"answer\"])\n",
        "\n",
        "dataset = Dataset.from_dict(data)\n"
      ],
      "metadata": {
        "id": "504xis-FSBPN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize Dataset"
      ],
      "metadata": {
        "id": "zj3lSbA9SHz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['question'], examples['context'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "2ce1ea5cbcf04da28df8f5726b3f7c20",
            "a4598918f0674aeb920b4c74d1e8c5c6",
            "5a6025f60ebc4870bcf7c9ef9a3f10f8",
            "59ff1aefaa8344b6918ef4e768907782",
            "9479b060b23c46c0ab8c24b3fdfbeb18",
            "fe73ac18b2794f84a85f1399e83c40ad",
            "3ce95092c92541c18b8b5be6ed96fe89",
            "188fa50ba3e342f19d07f8f702d5ce9a",
            "b7a45f478ebf46aebe85288e690866da",
            "d709721ba77c44c9a0244b87b09d5d86",
            "a8aa96959fcf41ff9a4d852c5f34b722"
          ]
        },
        "id": "LVvQsc8cSJpE",
        "outputId": "da39c4f4-e995-43e3-d854-07647f350fec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce1ea5cbcf04da28df8f5726b3f7c20"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "vNrok0sqZBqN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers[torch] accelerate -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8gIPW1kT9IV",
        "outputId": "9038270f-9446-4113-f637-69e1721d2a56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune the Model"
      ],
      "metadata": {
        "id": "6W8JzkT-SPE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JoYkGjMFSSd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "# Subclass Trainer to override compute_loss method\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Check if loss is None and handle it\n",
        "        if loss is None:\n",
        "            # This can happen if the loss is not calculated in the model (e.g., for evaluation)\n",
        "            return None if return_outputs else torch.tensor(0.0, device=self.args.device)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Custom Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "thjD42VXSMyl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define a tensor and set requires_grad to True\n",
        "tensor = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n"
      ],
      "metadata": {
        "id": "y_TV8Jt5bI9I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "class CustomBertForQuestionAnswering(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.qa_outputs = nn.Linear(config.hidden_size, 2)  # 2 because we're predicting start and end positions\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, start_positions=None, end_positions=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "        logits = self.qa_outputs(sequence_output)\n",
        "\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2  # You can adjust this formula as needed\n",
        "        else:\n",
        "            total_loss = None\n",
        "\n",
        "        return total_loss, start_logits, end_logits\n"
      ],
      "metadata": {
        "id": "BvaqVgy8dxbf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Subclass Trainer to override compute_loss method\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        if loss is None:\n",
        "            loss = torch.tensor(0.0, device=outputs.start_logits.device)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Custom Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Ensure all model parameters require gradients\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Print the names of parameters that require gradients\n",
        "print(\"Parameters requiring gradients:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    trainer.train()\n",
        "except RuntimeError as e:\n",
        "    print(\"RuntimeError:\", e)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(\"./ssi_bert_model\")\n",
        "tokenizer.save_pretrained(\"./ssi_bert_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XytRmmQRbqiI",
        "outputId": "5270656a-c453-48c3-8161-9f9fe9e20a98"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters requiring gradients:\n",
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "qa_outputs.weight\n",
            "qa_outputs.bias\n",
            "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./ssi_bert_model/tokenizer_config.json',\n",
              " './ssi_bert_model/special_tokens_map.json',\n",
              " './ssi_bert_model/vocab.txt',\n",
              " './ssi_bert_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Test the Model"
      ],
      "metadata": {
        "id": "nEzNtvBpSTx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('./ssi_bert_model')\n",
        "model = BertForQuestionAnswering.from_pretrained('./ssi_bert_model')\n",
        "\n",
        "# Function to answer questions\n",
        "def answer_question(question, context):\n",
        "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "    return answer\n",
        "\n",
        "# Example usage\n",
        "context = \" \".join([\n",
        "    \"Surgical Site Infections (SSIs) are infections that occur after surgery in the part of the body where the surgery took place.\",\n",
        "    \"SSIs are typically caused by bacteria that enter the incision site during surgery or in the days following surgery.\",\n",
        "    \"SSIs can be prevented by maintaining proper hygiene, using sterile equipment, and administering antibiotics before surgery.\",\n",
        "    \"Symptoms of SSIs include redness and swelling at the incision site, pain or tenderness, and pus or drainage from the wound.\",\n",
        "    \"Treatment for SSIs typically involves antibiotics and, in some cases, additional surgery to remove infected tissue.\"\n",
        "])\n",
        "\n",
        "questions = [\n",
        "    \"What are Surgical Site Infections (SSIs)?\",\n",
        "    \"What are the common causes of SSIs?\",\n",
        "    \"How can SSIs be prevented?\",\n",
        "    \"What are the symptoms of SSIs?\",\n",
        "    \"How are SSIs treated?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer_question(question, context)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OPZsD3wSUb8",
        "outputId": "fc04ec96-97ab-4c77-a88b-e261ed79472b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are Surgical Site Infections (SSIs)?\n",
            "Answer: \n",
            "\n",
            "Question: What are the common causes of SSIs?\n",
            "Answer: \n",
            "\n",
            "Question: How can SSIs be prevented?\n",
            "Answer: be prevented by maintaining proper hygiene , using sterile\n",
            "\n",
            "Question: What are the symptoms of SSIs?\n",
            "Answer: \n",
            "\n",
            "Question: How are SSIs treated?\n",
            "Answer: \n",
            "\n"
          ]
        }
      ]
    }
  ]
}